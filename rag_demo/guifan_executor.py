"""
executor_guifan.py
å»ºç­‘è§„èŒƒåº“ä¸“ç”¨æ‰§è¡Œå™¨
é€»è¾‘ï¼šæ„å›¾è¯†åˆ« -> åˆ†çº§æ£€ç´¢ -> [é€šç”¨ > ç±»å‹ > åœ°æ–¹] -> ä¸¥æ ¼JSONè¾“å‡º
"""
import json
from typing import List, Dict, TypedDict, Optional
from langchain_core.documents import Document
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel, Field

# å¼•å…¥åŸºç¡€ç»„ä»¶ (å‡è®¾åœ¨ executor.py å’Œ embeddings.py ä¸­)
from executor import RAGExecutor, SimilarityReranker
from embeddings import DoubaoVisionEmbeddings

# --- 1. å®šä¹‰ State ---
class GuiFanState(TypedDict):
    query: str
    location: str
    building_type: str
    mandatory_docs: List[Document]
    type_docs: List[Document]
    local_docs: List[Document]
    final_response: str

# --- 2. æå–å™¨æ¨¡å‹ ---
class QueryAnalysis(BaseModel):
    location: Optional[str] = Field(description="é¡¹ç›®æ‰€åœ¨çš„åŸå¸‚æˆ–çœä»½", default="")
    building_type: Optional[str] = Field(description="å»ºç­‘çš„åŠŸèƒ½ç±»å‹", default="")

class GuiFanExecutor(RAGExecutor):
    """å»ºç­‘è§„èŒƒåº“ RAG æ‰§è¡Œå™¨ (é€šç”¨ä¼˜å…ˆç‰ˆ)"""

    def __init__(self, llm, embedding_function=None, persist_dir: str = "./chroma_db", 
                 collection_name: str = "guifan", model_name: str = "doubao-pro-32k",
                 top_k: int = 5):
        
        if embedding_function is None:
            embedding_function = DoubaoVisionEmbeddings()
        
        reranker = SimilarityReranker(embedding_function)
        
        super().__init__(
            llm=llm,
            embedding_function=embedding_function,
            persist_dir=persist_dir,
            collection_name=collection_name,
            model_name=model_name,
            reranker=reranker,
            top_k=top_k
        )

    # ============================================================
    # æ ¸å¿ƒï¼šPrompt å®šä¹‰ (å·²è°ƒæ•´ä¸º é€šç”¨ > ç±»å‹ > åœ°æ–¹)
    # ============================================================

    def _get_generate_prompt(self, question: str, context: str, loc: str, typ: str) -> str:
        """
        æ„å»ºç”Ÿæˆæç¤ºè¯
        """
        return (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å»ºç­‘è§„èŒƒå’¨è¯¢ä¸“å®¶ã€‚è¯·åŸºäºæ£€ç´¢åˆ°çš„æ³•è§„åº“ï¼Œå›ç­”è®¾è®¡å¸ˆçš„é—®é¢˜ã€‚\n\n"
            
            "ã€ä»²è£é€»è¾‘ - ä¸¥æ ¼æ‰§è¡Œã€‘\n"
            "è¯·éµå¾ªä»¥ä¸‹ **ä¼˜å…ˆçº§é€’å‡** çš„é¡ºåºè§£å†³å†²çªï¼š\n"
            "1. **ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šé€šç”¨/å¼ºæ¡è§„èŒƒ** (GB 55xxx / GB 50xxx)ã€‚è¿™æ˜¯å›½å®¶åº•çº¿ï¼Œæ‹¥æœ‰æœ€é«˜è§£é‡Šæƒã€‚å¦‚æœå…¶ä»–è§„èŒƒä¸æ­¤å†²çªï¼Œä»¥é€šç”¨è§„èŒƒä¸ºå‡†ã€‚\n"
            "2. **ç¬¬äºŒä¼˜å…ˆçº§ï¼šç±»å‹è§„èŒƒ** (å¦‚{typ}è§„èŒƒ)ã€‚é’ˆå¯¹ç‰¹å®šåŠŸèƒ½çš„å…·ä½“è¦æ±‚ã€‚åœ¨ä¸è¿åé€šç”¨è§„èŒƒçš„å‰æä¸‹ï¼Œæ‰§è¡Œç±»å‹è§„èŒƒã€‚\n"
            "3. **ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šåœ°æ–¹è§„èŒƒ** (å¦‚{loc}å¯¼åˆ™)ã€‚ä»…ä½œä¸ºè¡¥å……å‚è€ƒã€‚å¦‚æœåœ°æ–¹è§„èŒƒçš„è¦æ±‚ä½äºé€šç”¨æˆ–ç±»å‹è§„èŒƒï¼Œåˆ™**æ— æ•ˆ**ï¼›å¦‚æœæ›´ä¸¥æ ¼ï¼Œå¯ä½œä¸ºå»ºè®®æå‡ºã€‚\n\n"

            "ã€è¾“å‡ºæ ¼å¼ - çº¯ JSONã€‘\n"
            "è¯·ç›´æ¥è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON æ•°ç»„ï¼Œä¸¥ç¦ Markdownï¼Œä¸¥ç¦è§£é‡Šæ–‡å­—ã€‚\n"
            "JSON ç»“æ„ï¼š\n"
            "[\n"
            "  {\n"
            "    \"æ¡æ¬¾åç§°\": \"è§„èŒƒå…¨å + æ¡æ–‡ç¼–å·\",\n"
            "    \"è§„èŒƒè¦æ±‚\": \"(å¿…é¡»æ˜¯åŸæ–‡ï¼Œä¸å¯æ”¹å†™)\",\n"
            "    \"é›·åŒºæç¤º\": \"1. (å†²çªåˆ†æï¼šæ˜ç¡®æŒ‡å‡ºè¯¥æ¡æ¬¾å±äºå“ªä¸ªä¼˜å…ˆçº§ï¼Œæ˜¯å¦è¦†ç›–äº†å…¶ä»–è§„èŒƒ) 2. (å®æ“å»ºè®®ï¼šç»“åˆé¡¹ç›®æ˜¯'{loc}çš„{typ}'ç»™å‡ºå»ºè®®)\"\n"
            "  }\n"
            "]\n\n"
            
            "ã€ä¸¥æ ¼çº¦æŸã€‘\n"
            "- å¿…é¡»åŒ…å«ä¸Šè¿° 3 ä¸ªå­—æ®µã€‚\n"
            "- å¦‚æœåœ¨æ£€ç´¢ä¸Šä¸‹æ–‡ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¯·è¿”å›ç©ºæ•°ç»„ []ã€‚\n"
            "- ä¸è¦ç¼–é€ ä¿¡æ¯ã€‚\n\n"

            f"è®¾è®¡å¸ˆé—®é¢˜: {question}\n"
            f"é¡¹ç›®èƒŒæ™¯: åœ°ç‚¹={loc}, ç±»å‹={typ}\n\n"
            f"å‚è€ƒè§„èŒƒä¸Šä¸‹æ–‡:\n{context}"
        )

    # ============================================================
    # LangGraph å·¥ä½œæµ
    # ============================================================

    def _build_workflow(self):
        workflow = StateGraph(GuiFanState)

        # èŠ‚ç‚¹æ·»åŠ 
        workflow.add_node("analyze_query", self._analyze_query_node)
        workflow.add_node("retrieve_mandatory", self._retrieve_mandatory_node)
        workflow.add_node("retrieve_type", self._retrieve_type_node)
        workflow.add_node("retrieve_local", self._retrieve_local_node)
        workflow.add_node("conflict_resolution", self._conflict_resolution_node)

        # è¾¹å®šä¹‰
        workflow.add_edge(START, "analyze_query")
        
        # åˆ†æµ
        workflow.add_edge("analyze_query", "retrieve_mandatory")
        workflow.add_edge("analyze_query", "retrieve_type")
        workflow.add_edge("analyze_query", "retrieve_local")
        
        # æ±‡èš
        workflow.add_edge("retrieve_mandatory", "conflict_resolution")
        workflow.add_edge("retrieve_type", "conflict_resolution")
        workflow.add_edge("retrieve_local", "conflict_resolution")
        
        workflow.add_edge("conflict_resolution", END)

        self.app = workflow.compile()

    # ============================================================
    # èŠ‚ç‚¹å®ç°
    # ============================================================

    def _analyze_query_node(self, state: GuiFanState):
        """æ„å›¾åˆ†æ"""
        query = state["query"]
        print(f"ğŸ§  [Analyzer] åˆ†æä¸­...")
        structured_llm = self.llm.with_structured_output(QueryAnalysis)
        analysis = structured_llm.invoke(f"æå–ï¼š1.åœ°ç‚¹ 2.å»ºç­‘ç±»å‹ã€‚\né—®é¢˜ï¼š{query}")
        print(f"   -> åœ°ç‚¹: '{analysis.location}', ç±»å‹: '{analysis.building_type}'")
        return {"location": analysis.location, "building_type": analysis.building_type}

    def _retrieve_mandatory_node(self, state: GuiFanState):
        """æ£€ç´¢é€šç”¨/å¼ºæ¡"""
        query = state["query"]
        try:
            # å°è¯•æ£€ç´¢ mandatory_general å’Œ national_standard
            docs = self.vectorstore.similarity_search(
                query, k=3, filter={"type": "mandatory_general"}
            )
            # è¡¥å……æ£€ç´¢å›½æ ‡ä½œä¸ºå…œåº•
            if len(docs) < 3:
                docs += self.vectorstore.similarity_search(
                    query, k=2, filter={"type": "national_standard"}
                )
        except:
            docs = []
        return {"mandatory_docs": docs}

    def _retrieve_type_node(self, state: GuiFanState):
        """æ£€ç´¢ç±»å‹è§„èŒƒ"""
        query = state["query"]
        b_type = state["building_type"]
        if not b_type: return {"type_docs": []}
        
        # ç®€å•æ£€ç´¢ + è¿‡æ»¤
        docs = self.vectorstore.similarity_search(query, k=4)
        filtered = [d for d in docs if b_type in d.metadata.get('doc_name', '')]
        return {"type_docs": filtered if filtered else docs[:2]}

    def _retrieve_local_node(self, state: GuiFanState):
        """æ£€ç´¢åœ°æ–¹è§„èŒƒ"""
        query = state["query"]
        loc = state["location"]
        if not loc: return {"local_docs": []}
        
        try:
            # æ„é€ å¸¦åœ°ç‚¹çš„æŸ¥è¯¢
            docs = self.vectorstore.similarity_search(
                f"{loc} {query}", k=3, filter={"type": "local_guide"}
            )
            # äºŒæ¬¡ç¡®è®¤æ–‡æ¡£ååŒ…å«åœ°ç‚¹
            final_docs = [d for d in docs if loc in d.metadata.get('doc_name', '')]
        except:
            final_docs = []
        return {"local_docs": final_docs}

    def _conflict_resolution_node(self, state: GuiFanState):
        """ä»²è£ä¸ç”Ÿæˆ"""
        print(f"âš–ï¸ [Arbiter] æ­£åœ¨æ ¹æ® [é€šç”¨>ç±»å‹>åœ°æ–¹] é€»è¾‘ç”Ÿæˆ...")
        
        mandatory = state.get("mandatory_docs", [])
        type_docs = state.get("type_docs", [])
        local_docs = state.get("local_docs", [])
        
        query = state["query"]
        loc = state["location"]
        typ = state["building_type"]

        # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        context_str = self._format_docs_for_arbitration(mandatory, type_docs, local_docs, loc, typ)
        # è·å– Prompt
        prompt_text = self._get_generate_prompt(query, context_str, loc, typ)
        
        response = self.llm.invoke(prompt_text)
        content = response.content.strip()

        # JSON æ¸…æ´—
        if content.startswith("```json"): content = content[7:]
        if content.startswith("```"): content = content[3:]
        if content.endswith("```"): content = content[:-3]
        
        return {"final_response": content.strip()}

    # ============================================================
    # è¾…åŠ©æ–¹æ³• (æ–‡æ¡£æ’åºå·²è°ƒæ•´)
    # ============================================================

    def _format_docs_for_arbitration(self, mandatory, typed, local, loc, typ) -> str:
        """
        æŒ‰ç…§ é€šç”¨ -> ç±»å‹ -> åœ°æ–¹ çš„é¡ºåºæ‹¼æ¥æ–‡æ¡£ï¼Œæ–¹ä¾¿ LLM è®¤çŸ¥ä¼˜å…ˆçº§
        """
        formatted = []
        
        # 1. é€šç”¨/å¼ºæ¡ (æœ€é«˜ä¼˜å…ˆçº§)
        formatted.append("ğŸ”´ ã€ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šé€šç”¨/å¼ºåˆ¶æ€§è§„èŒƒã€‘(å›½å®¶åº•çº¿ï¼Œå¿…é¡»éµå®ˆ)")
        if mandatory:
            for i, d in enumerate(mandatory):
                formatted.append(f"   [{i+1}] ã€Š{d.metadata.get('doc_name')}ã€‹: {d.page_content.strip()}")
        else:
            formatted.append("   (æœªæ£€ç´¢åˆ°ç›¸å…³å¼ºæ¡)")

        # 2. ç±»å‹è§„èŒƒ
        formatted.append(f"\nğŸ”µ ã€ç¬¬äºŒä¼˜å…ˆçº§ï¼š{typ} ç±»å‹è§„èŒƒã€‘(åŠŸèƒ½æ€§è¦æ±‚)")
        if typed:
            for i, d in enumerate(typed):
                formatted.append(f"   [{i+1}] ã€Š{d.metadata.get('doc_name')}ã€‹: {d.page_content.strip()}")
        else:
            formatted.append(f"   (æœªæ£€ç´¢åˆ° {typ} ä¸“å±è§„èŒƒ)")

        # 3. åœ°æ–¹è§„èŒƒ
        formatted.append(f"\nğŸŸ¢ ã€ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼š{loc} åœ°æ–¹è§„èŒƒã€‘(è¡¥å……å‚è€ƒ)")
        if local:
            for i, d in enumerate(local):
                formatted.append(f"   [{i+1}] ã€Š{d.metadata.get('doc_name')}ã€‹: {d.page_content.strip()}")
        else:
            formatted.append(f"   (æœªæ£€ç´¢åˆ° {loc} åœ°æ–¹å¯¼åˆ™)")
        
        return "\n".join(formatted)

    # å ä½ç¬¦
    def _format_documents(self, docs): return ""
    def _get_rewrite_prompt(self, q): return q
    def _get_grade_prompt(self, q, c): return "yes"

    def run(self):
        print(f"\n>>> å»ºç­‘è§„èŒƒæŸ¥è¯¢ç³»ç»Ÿ (Model: {self.model_name})")
        print(">>> é€»è¾‘: æ„å›¾ -> [é€šç”¨>ç±»å‹>åœ°æ–¹] -> JSON")
        
        while True:
            try:
                user_input = input("\nUser: ")
                if user_input.lower() in ["q", "quit", "exit"]: break
                result = self.app.invoke({"query": user_input})
                
                try:
                    data = json.loads(result['final_response'])
                    print(f"\nAssistant (JSON):\n{json.dumps(data, indent=2, ensure_ascii=False)}\n")
                except:
                    print(f"\nAssistant (Raw):\n{result['final_response']}\n")
            except Exception as e:
                print(f"[Error] {e}")