# è±†åŒ…å¤§æ¨¡å‹é›†æˆ - å¼€å‘æŒ‡å—

## æ–‡æ¡£ä¿¡æ¯
- **ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2026-01-28
- **ç›®æ ‡è¯»è€…**: å¼€å‘äººå‘˜

---

## ä¸€ã€å¼€å‘å‡†å¤‡

### 1.1 å‰ç½®æ¡ä»¶

- [x] äº†è§£ç°æœ‰spec_locatoré¡¹ç›®æ¶æ„
- [x] ç†Ÿæ‚‰PaddleOCRè¯†åˆ«æµç¨‹
- [x] äº†è§£FastAPIæ¡†æ¶
- [x] æœ‰è±†åŒ…APIä½¿ç”¨ç»éªŒï¼ˆå¯å‚è€ƒrag_demoæ¨¡å—ï¼‰

### 1.2 å¼€å‘ç¯å¢ƒ

**å¿…éœ€è½¯ä»¶**ï¼š
- Python 3.8+
- VS Code æˆ– PyCharm
- Git

**ä¾èµ–åŒ…å®‰è£…**ï¼š
```bash
# è¿›å…¥é¡¹ç›®è™šæ‹Ÿç¯å¢ƒ
cd d:\projects\liuzong\spec_locator
.\.venv\Scripts\Activate.ps1

# å®‰è£…æ–°ä¾èµ–
pip install volcenginesdkarkruntime tenacity
```

### 1.3 è·å–è±†åŒ…APIå¯†é’¥

1. è®¿é—®ï¼šhttps://console.volcengine.com/ark
2. åˆ›å»ºæˆ–è·å–APIå¯†é’¥
3. é…ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   # Windows
   set DOUBAO_API_KEY=your_api_key_here
   
   # Linux/Mac
   export DOUBAO_API_KEY=your_api_key_here
   ```

---

## äºŒã€å®æ–½æ­¥éª¤

### Phase 1: åŸºç¡€æ¨¡å—å®ç°ï¼ˆDay 1-2ï¼‰

#### Step 1.1: åˆ›å»ºLLMæ¨¡å—ç›®å½•ç»“æ„

```bash
mkdir spec_locator\llm
New-Item spec_locator\llm\__init__.py
New-Item spec_locator\llm\doubao_engine.py
New-Item spec_locator\llm\prompt_templates.py
New-Item spec_locator\llm\response_parser.py
```

#### Step 1.2: å®ç°Promptæ¨¡æ¿ç®¡ç†å™¨

**æ–‡ä»¶**: `spec_locator/llm/prompt_templates.py`

```python
"""
Promptæ¨¡æ¿ç®¡ç†
"""

class PromptManager:
    """Promptæ¨¡æ¿ç®¡ç†å™¨"""
    
    # ç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å»ºç­‘è§„èŒƒå›¾çº¸è¯†åˆ«ä¸“å®¶ï¼Œæ“…é•¿ä»CADæˆªå›¾ä¸­è¯†åˆ«è§„èŒƒç¼–å·å’Œé¡µç ã€‚"""
    
    # ä¸»è¯†åˆ«Promptï¼ˆç‰ˆæœ¬1ï¼‰
    RECOGNITION_PROMPT_V1 = """
è¯·ä»”ç»†åˆ†æè¿™å¼ CADæˆªå›¾ï¼Œè¯†åˆ«å…¶ä¸­çš„ï¼š

1. **è§„èŒƒç¼–å·**ï¼šæ ¼å¼å¦‚ 12J2ã€20G908-1ã€L13J5-1ã€23J908-8
   - é€šå¸¸ç”±2-3ä½æ•°å­— + å­—æ¯ + æ•°å­—ç»„æˆ
   - å¯èƒ½æœ‰å­—æ¯å‰ç¼€ï¼ˆå¦‚Lã€è‹ç­‰åœ°æ–¹æ ‡å‡†ï¼‰
   - å¯èƒ½æœ‰çŸ­æ¨ªçº¿å’Œåç¼€æ•°å­—

2. **é¡µç **ï¼šæ ¼å¼å¦‚ C11ã€C11-2ã€P23ã€1-11
   - é€šå¸¸ç”±1ä¸ªå­—æ¯ + æ•°å­—ç»„æˆ
   - å¯èƒ½æœ‰çŸ­æ¨ªçº¿å’Œåç¼€æ•°å­—
   - ä¸€èˆ¬ä¸è§„èŒƒç¼–å·ä½ç½®ç›¸é‚»

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
```json
{
    "spec_code": "è¯†åˆ«åˆ°çš„è§„èŒƒç¼–å·",
    "page_code": "è¯†åˆ«åˆ°çš„é¡µç ",
    "confidence": 0.95,
    "reasoning": "è¯†åˆ«ä¾æ®è¯´æ˜"
}
```

å¦‚æœæ— æ³•è¯†åˆ«ï¼Œè¯·è¿”å›ï¼š
```json
{
    "spec_code": null,
    "page_code": null,
    "confidence": 0.0,
    "reasoning": "æ— æ³•è¯†åˆ«çš„åŸå› "
}
```
"""
    
    @classmethod
    def get_prompt(cls, version: str = "v1") -> str:
        """
        è·å–æŒ‡å®šç‰ˆæœ¬çš„Prompt
        
        Args:
            version: Promptç‰ˆæœ¬å·
            
        Returns:
            Promptæ–‡æœ¬
        """
        if version == "v1":
            return cls.RECOGNITION_PROMPT_V1
        else:
            raise ValueError(f"Unknown prompt version: {version}")
    
    @classmethod
    def build_messages(cls, image_base64: str, version: str = "v1") -> list:
        """
        æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        
        Args:
            image_base64: Base64ç¼–ç çš„å›¾ç‰‡
            version: Promptç‰ˆæœ¬
            
        Returns:
            æ¶ˆæ¯åˆ—è¡¨ï¼ˆé€‚ç”¨äºè±†åŒ…APIï¼‰
        """
        return [
            {
                "role": "system",
                "content": cls.SYSTEM_PROMPT
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    },
                    {
                        "type": "text",
                        "text": cls.get_prompt(version)
                    }
                ]
            }
        ]
```

#### Step 1.3: å®ç°å“åº”è§£æå™¨

**æ–‡ä»¶**: `spec_locator/llm/response_parser.py`

```python
"""
å¤§æ¨¡å‹å“åº”è§£æå™¨
"""

import re
import json
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


class ResponseParser:
    """å¤§æ¨¡å‹å“åº”è§£æå™¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    
    @staticmethod
    def parse(response_text: str) -> Dict[str, Any]:
        """
        è§£æå¤§æ¨¡å‹å“åº”
        
        Args:
            response_text: å¤§æ¨¡å‹è¿”å›çš„æ–‡æœ¬
            
        Returns:
            è§£æåçš„ç»“æ„åŒ–æ•°æ®
        """
        # å°è¯•å¤šç§è§£ææ–¹å¼
        parsers = [
            ResponseParser._parse_json_direct,
            ResponseParser._parse_json_from_markdown,
            ResponseParser._parse_json_from_text,
            ResponseParser._parse_natural_language
        ]
        
        for parser in parsers:
            try:
                result = parser(response_text)
                if result and ResponseParser.validate(result):
                    logger.info(f"Successfully parsed using {parser.__name__}")
                    return result
            except Exception as e:
                logger.debug(f"Parser {parser.__name__} failed: {e}")
                continue
        
        # æ‰€æœ‰è§£æå™¨éƒ½å¤±è´¥
        logger.error(f"Failed to parse response: {response_text[:200]}")
        return {
            "spec_code": None,
            "page_code": None,
            "confidence": 0.0,
            "reasoning": "Failed to parse model response"
        }
    
    @staticmethod
    def _parse_json_direct(text: str) -> Optional[Dict]:
        """ç›´æ¥è§£æJSON"""
        return json.loads(text.strip())
    
    @staticmethod
    def _parse_json_from_markdown(text: str) -> Optional[Dict]:
        """ä»Markdownä»£ç å—ä¸­æå–JSON"""
        # åŒ¹é… ```json ... ``` æˆ– ``` ... ```
        pattern = r"```(?:json)?\s*\n(.*?)\n```"
        match = re.search(pattern, text, re.DOTALL)
        if match:
            json_str = match.group(1)
            return json.loads(json_str)
        return None
    
    @staticmethod
    def _parse_json_from_text(text: str) -> Optional[Dict]:
        """ä»æ–‡æœ¬ä¸­æå–JSONå¯¹è±¡"""
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
        start = text.find('{')
        if start == -1:
            return None
        
        # ç®€å•çš„å¤§æ‹¬å·åŒ¹é…
        depth = 0
        for i in range(start, len(text)):
            if text[i] == '{':
                depth += 1
            elif text[i] == '}':
                depth -= 1
                if depth == 0:
                    json_str = text[start:i+1]
                    return json.loads(json_str)
        return None
    
    @staticmethod
    def _parse_natural_language(text: str) -> Optional[Dict]:
        """ä»è‡ªç„¶è¯­è¨€ä¸­æå–ä¿¡æ¯ï¼ˆæœ€åçš„å…œåº•æ–¹æ¡ˆï¼‰"""
        # æå–è§„èŒƒç¼–å·
        spec_pattern = r'([A-Z]{0,2}\d{2,3}\s*[A-Z]\s*\d{1,3}(?:-\d+)?)'
        spec_matches = re.findall(spec_pattern, text)
        
        # æå–é¡µç 
        page_pattern = r'([A-Z]\d{1,3}(?:-\d+)?)'
        page_matches = re.findall(page_pattern, text)
        
        if spec_matches and page_matches:
            return {
                "spec_code": spec_matches[0].replace(' ', ''),
                "page_code": page_matches[0],
                "confidence": 0.5,  # è¾ƒä½ç½®ä¿¡åº¦
                "reasoning": "Extracted from natural language"
            }
        return None
    
    @staticmethod
    def validate(data: Dict) -> bool:
        """
        éªŒè¯è§£æç»“æœçš„æœ‰æ•ˆæ€§
        
        Args:
            data: è§£æåçš„æ•°æ®
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        required_keys = {"spec_code", "page_code", "confidence"}
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not all(key in data for key in required_keys):
            return False
        
        # æ£€æŸ¥ç½®ä¿¡åº¦èŒƒå›´
        if not (0.0 <= data["confidence"] <= 1.0):
            return False
        
        return True
```

#### Step 1.4: å®ç°è±†åŒ…å¼•æ“

**æ–‡ä»¶**: `spec_locator/llm/doubao_engine.py`

```python
"""
è±†åŒ…è§†è§‰å¤§æ¨¡å‹å¼•æ“
"""

import os
import logging
import base64
import cv2
import numpy as np
from typing import Dict, Any
from tenacity import retry, stop_after_attempt, wait_exponential

try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    raise ImportError("Please install: pip install volcenginesdkarkruntime")

from spec_locator.llm.prompt_templates import PromptManager
from spec_locator.llm.response_parser import ResponseParser

logger = logging.getLogger(__name__)


class DoubaoEngine:
    """è±†åŒ…è§†è§‰å¤§æ¨¡å‹å¼•æ“"""
    
    def __init__(
        self,
        api_key: str = None,
        model: str = "doubao-vision-pro",
        timeout: int = 30,
        max_retries: int = 2,
        prompt_version: str = "v1"
    ):
        """
        åˆå§‹åŒ–è±†åŒ…å¼•æ“
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: æ¨¡å‹åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            prompt_version: Promptç‰ˆæœ¬
        """
        self.api_key = api_key or os.getenv("DOUBAO_API_KEY") or os.getenv("ARK_API_KEY")
        if not self.api_key:
            raise ValueError("DOUBAO_API_KEY not set in environment or parameters")
        
        self.client = Ark(api_key=self.api_key)
        self.model = model
        self.timeout = timeout
        self.max_retries = max_retries
        self.prompt_version = prompt_version
        
        logger.info(f"DoubaoEngine initialized: model={model}, timeout={timeout}s")
    
    def recognize(self, image: np.ndarray) -> Dict[str, Any]:
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„è§„èŒƒç¼–å·å’Œé¡µç 
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼Œnumpyæ•°ç»„ï¼‰
            
        Returns:
            {
                "success": True/False,
                "spec_code": "12J2",
                "page_code": "C11",
                "confidence": 0.95,
                "reasoning": "è¯†åˆ«ä¾æ®",
                "raw_response": "åŸå§‹å“åº”"
            }
        """
        try:
            # 1. å›¾åƒè½¬Base64
            image_base64 = self._image_to_base64(image)
            
            # 2. è°ƒç”¨API
            logger.info("Calling Doubao API...")
            raw_response = self._call_api_with_retry(image_base64)
            logger.info(f"API response received: {raw_response[:200]}...")
            
            # 3. è§£æå“åº”
            parsed_result = ResponseParser.parse(raw_response)
            
            # 4. æ„å»ºè¿”å›ç»“æœ
            result = {
                "success": parsed_result.get("spec_code") is not None and parsed_result.get("page_code") is not None,
                "spec_code": parsed_result.get("spec_code"),
                "page_code": parsed_result.get("page_code"),
                "confidence": parsed_result.get("confidence", 0.0),
                "reasoning": parsed_result.get("reasoning", ""),
                "raw_response": raw_response
            }
            
            logger.info(f"Recognition result: {result['spec_code']} / {result['page_code']} (conf={result['confidence']})")
            return result
            
        except Exception as e:
            logger.error(f"DoubaoEngine recognition failed: {e}", exc_info=True)
            return {
                "success": False,
                "spec_code": None,
                "page_code": None,
                "confidence": 0.0,
                "reasoning": f"Error: {str(e)}",
                "raw_response": ""
            }
    
    def _image_to_base64(self, image: np.ndarray) -> str:
        """
        å°†numpyå›¾åƒè½¬æ¢ä¸ºBase64ç¼–ç 
        
        Args:
            image: numpyæ•°ç»„å›¾åƒ
            
        Returns:
            Base64ç¼–ç å­—ç¬¦ä¸²
        """
        # ç¡®ä¿æ˜¯RGBæ ¼å¼ï¼ˆè±†åŒ…APIè¦æ±‚ï¼‰
        if len(image.shape) == 3 and image.shape[2] == 3:
            # OpenCVä½¿ç”¨BGRï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ç¼–ç ä¸ºJPEG
        success, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 95])
        if not success:
            raise ValueError("Failed to encode image")
        
        # è½¬Base64
        return base64.b64encode(buffer).decode('utf-8')
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        reraise=True
    )
    def _call_api_with_retry(self, image_base64: str) -> str:
        """
        è°ƒç”¨è±†åŒ…APIï¼ˆå¸¦é‡è¯•ï¼‰
        
        Args:
            image_base64: Base64ç¼–ç çš„å›¾ç‰‡
            
        Returns:
            APIå“åº”æ–‡æœ¬
        """
        # æ„å»ºæ¶ˆæ¯
        messages = PromptManager.build_messages(image_base64, self.prompt_version)
        
        # è°ƒç”¨API
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            timeout=self.timeout
        )
        
        return response.choices[0].message.content
    
    def warmup(self):
        """é¢„çƒ­ï¼ˆå¯é€‰ï¼Œç”¨äºæµ‹è¯•è¿æ¥ï¼‰"""
        logger.info("DoubaoEngine warmup - testing connection...")
        # å¯ä»¥å‘é€ä¸€ä¸ªå°çš„æµ‹è¯•è¯·æ±‚
        pass
```

#### Step 1.5: åˆ›å»ºæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶

**æ–‡ä»¶**: `spec_locator/llm/__init__.py`

```python
"""
å¤§æ¨¡å‹è¯†åˆ«æ¨¡å—
"""

from spec_locator.llm.doubao_engine import DoubaoEngine
from spec_locator.llm.prompt_templates import PromptManager
from spec_locator.llm.response_parser import ResponseParser

__all__ = [
    "DoubaoEngine",
    "PromptManager",
    "ResponseParser"
]
```

#### Step 1.6: å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `spec_locator/tests/test_llm_module.py`

```python
"""
LLMæ¨¡å—å•å…ƒæµ‹è¯•
"""

import pytest
import numpy as np
from spec_locator.llm import DoubaoEngine, ResponseParser, PromptManager


class TestResponseParser:
    """æµ‹è¯•å“åº”è§£æå™¨"""
    
    def test_parse_json_direct(self):
        """æµ‹è¯•ç›´æ¥JSONè§£æ"""
        json_str = '{"spec_code": "12J2", "page_code": "C11", "confidence": 0.95}'
        result = ResponseParser.parse(json_str)
        assert result["spec_code"] == "12J2"
        assert result["page_code"] == "C11"
    
    def test_parse_json_from_markdown(self):
        """æµ‹è¯•ä»Markdownæå–JSON"""
        markdown_str = """
è¿™æ˜¯è¯†åˆ«ç»“æœï¼š
```json
{
    "spec_code": "20G908-1",
    "page_code": "P23",
    "confidence": 0.88
}
```
"""
        result = ResponseParser.parse(markdown_str)
        assert result["spec_code"] == "20G908-1"
        assert result["page_code"] == "P23"
    
    def test_parse_natural_language(self):
        """æµ‹è¯•è‡ªç„¶è¯­è¨€æå–"""
        nl_str = "è¯†åˆ«åˆ°è§„èŒƒç¼–å·ä¸º 12J2ï¼Œé¡µç ä¸º C11"
        result = ResponseParser.parse(nl_str)
        assert result["spec_code"] == "12J2"
        assert result["page_code"] == "C11"


class TestPromptManager:
    """æµ‹è¯•Promptç®¡ç†å™¨"""
    
    def test_get_prompt_v1(self):
        """æµ‹è¯•è·å–v1 Prompt"""
        prompt = PromptManager.get_prompt("v1")
        assert "è§„èŒƒç¼–å·" in prompt
        assert "é¡µç " in prompt
        assert "JSON" in prompt
    
    def test_build_messages(self):
        """æµ‹è¯•æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        image_base64 = "dummy_base64_string"
        messages = PromptManager.build_messages(image_base64, "v1")
        assert len(messages) == 2
        assert messages[0]["role"] == "system"
        assert messages[1]["role"] == "user"


@pytest.mark.skipif(not os.getenv("DOUBAO_API_KEY"), reason="API key not set")
class TestDoubaoEngine:
    """æµ‹è¯•è±†åŒ…å¼•æ“ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰"""
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        engine = DoubaoEngine()
        assert engine.model is not None
        assert engine.client is not None
    
    def test_image_to_base64(self):
        """æµ‹è¯•å›¾ç‰‡Base64ç¼–ç """
        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
        image = np.zeros((100, 100, 3), dtype=np.uint8)
        engine = DoubaoEngine()
        base64_str = engine._image_to_base64(image)
        assert isinstance(base64_str, str)
        assert len(base64_str) > 0


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

### Phase 2: Pipelineé›†æˆï¼ˆDay 3ï¼‰

#### Step 2.1: æ·»åŠ LLMé…ç½®

**æ–‡ä»¶**: `spec_locator/config/config.py`

åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼š

```python
# ===== å¤§æ¨¡å‹é…ç½® =====
class LLMConfig:
    """å¤§æ¨¡å‹é…ç½®"""
    
    # åŸºç¡€é…ç½®
    ENABLED = os.getenv("LLM_ENABLED", "true").lower() == "true"
    API_KEY = os.getenv("DOUBAO_API_KEY") or os.getenv("ARK_API_KEY")
    MODEL = os.getenv("LLM_MODEL", "doubao-vision-pro")
    
    # æ€§èƒ½é…ç½®
    TIMEOUT = int(os.getenv("LLM_TIMEOUT", "30"))  # ç§’
    MAX_RETRIES = int(os.getenv("LLM_MAX_RETRIES", "2"))
    
    # æ··åˆæ¨¡å¼é…ç½®
    AUTO_FALLBACK = os.getenv("LLM_AUTO_FALLBACK", "true").lower() == "true"
    OCR_CONFIDENCE_THRESHOLD = float(os.getenv("OCR_CONFIDENCE_THRESHOLD", "0.6"))
    
    # Prompté…ç½®
    PROMPT_VERSION = os.getenv("LLM_PROMPT_VERSION", "v1")
    
    @staticmethod
    def validate():
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if LLMConfig.ENABLED and not LLMConfig.API_KEY:
            logger.warning("LLM is enabled but DOUBAO_API_KEY is not set")
            return False
        return True
```

åŒæ—¶æ›´æ–° `__init__.py` å¯¼å‡ºï¼š

```python
from spec_locator.config.config import (
    # ... ç°æœ‰å¯¼å‡º
    LLMConfig,  # æ–°å¢
)

__all__ = [
    # ... ç°æœ‰å¯¼å‡º
    "LLMConfig",  # æ–°å¢
]
```

#### Step 2.2: ä¿®æ”¹Pipelineæ”¯æŒå¤šç­–ç•¥

**æ–‡ä»¶**: `spec_locator/core/pipeline.py`

åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥ï¼š

```python
from spec_locator.config import LLMConfig
from spec_locator.llm import DoubaoEngine
```

ä¿®æ”¹ `__init__` æ–¹æ³•ï¼š

```python
def __init__(
    self,
    use_gpu: bool = False,
    ocr_threshold: float = 0.3,
    max_distance: int = 100,
    data_dir: str = None,
    lazy_ocr: bool = True,
    recognition_method: str = "ocr",  # æ–°å¢å‚æ•°
    llm_api_key: str = None,          # æ–°å¢å‚æ•°
):
    """
    åˆå§‹åŒ–æµæ°´çº¿

    Args:
        # ... ç°æœ‰å‚æ•°è¯´æ˜
        recognition_method: è¯†åˆ«æ–¹å¼ ("ocr" | "llm" | "auto")
        llm_api_key: å¤§æ¨¡å‹APIå¯†é’¥
    """
    # ç°æœ‰åˆå§‹åŒ–ä»£ç ...
    
    # æ–°å¢ï¼šè¯†åˆ«æ–¹å¼é…ç½®
    self.recognition_method = recognition_method
    
    # æ–°å¢ï¼šåˆå§‹åŒ–LLMå¼•æ“ï¼ˆå¦‚æœéœ€è¦ï¼‰
    self.llm_engine = None
    if recognition_method in ["llm", "auto"] and LLMConfig.ENABLED:
        try:
            self.llm_engine = DoubaoEngine(
                api_key=llm_api_key or LLMConfig.API_KEY,
                model=LLMConfig.MODEL,
                timeout=LLMConfig.TIMEOUT,
                max_retries=LLMConfig.MAX_RETRIES,
                prompt_version=LLMConfig.PROMPT_VERSION
            )
            logger.info(f"âœ“ LLM Engine initialized (method={recognition_method})")
        except Exception as e:
            logger.error(f"Failed to initialize LLM engine: {e}")
            if recognition_method == "llm":
                raise  # llmæ¨¡å¼å¿…é¡»æˆåŠŸåˆå§‹åŒ–
```

åœ¨ `process` æ–¹æ³•å‰æ·»åŠ è·¯ç”±é€»è¾‘ï¼š

```python
def process(self, image: np.ndarray) -> Dict[str, Any]:
    """
    å¤„ç†å›¾åƒå¹¶è¿”å›è¯†åˆ«ç»“æœï¼ˆæ”¯æŒå¤šç§è¯†åˆ«æ–¹å¼ï¼‰

    Args:
        image: è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰

    Returns:
        åŒ…å«ç»“æœæˆ–é”™è¯¯çš„å­—å…¸
    """
    # æ ¹æ®è¯†åˆ«æ–¹å¼è·¯ç”±
    if self.recognition_method == "llm":
        return self._process_with_llm(image)
    elif self.recognition_method == "auto":
        return self._process_hybrid(image)
    else:  # "ocr" æˆ–é»˜è®¤
        return self._process_with_ocr(image)

def _process_with_ocr(self, image: np.ndarray) -> Dict[str, Any]:
    """OCRè¯†åˆ«æµç¨‹ï¼ˆåŸprocessæ–¹æ³•é€»è¾‘ï¼‰"""
    try:
        # åŸæœ‰çš„å®Œæ•´è¯†åˆ«é€»è¾‘...
        # ï¼ˆå°†åŸprocessæ–¹æ³•çš„å†…å®¹ç§»åˆ°è¿™é‡Œï¼‰
        pass
    except Exception as e:
        logger.error(f"OCR Pipeline error: {e}", exc_info=True)
        return self._error_response(ErrorCode.INTERNAL_ERROR)

def _process_with_llm(self, image: np.ndarray) -> Dict[str, Any]:
    """å¤§æ¨¡å‹è¯†åˆ«æµç¨‹ï¼ˆæ–°å¢ï¼‰"""
    try:
        if not self.llm_engine:
            return self._error_response(ErrorCode.LLM_NOT_CONFIGURED)
        
        logger.info("Processing with LLM...")
        llm_result = self.llm_engine.recognize(image)
        
        if not llm_result["success"]:
            return {
                "success": False,
                "method": "llm",
                "error_code": ErrorCode.NO_MATCH,
                "message": "LLM failed to recognize spec code or page code",
                "details": llm_result
            }
        
        # æŸ¥æ‰¾å¯¹åº”çš„PDFæ–‡ä»¶
        pdf_file = self.file_index.find_file(
            llm_result["spec_code"],
            llm_result["page_code"]
        )
        
        response = {
            "success": True,
            "method": "llm",
            "spec": {
                "code": llm_result["spec_code"],
                "page": llm_result["page_code"],
                "confidence": llm_result["confidence"],
            },
            "metadata": {
                "llm_reasoning": llm_result.get("reasoning", "")
            }
        }
        
        if pdf_file:
            response["file"] = {
                "path": pdf_file,
                "exists": True,
                "download_url": f"/api/download/{llm_result['spec_code']}/{llm_result['page_code']}"
            }
        else:
            response["file"] = {"exists": False}
        
        return response
        
    except Exception as e:
        logger.error(f"LLM Pipeline error: {e}", exc_info=True)
        return self._error_response(ErrorCode.INTERNAL_ERROR)

def _process_hybrid(self, image: np.ndarray) -> Dict[str, Any]:
    """æ··åˆè¯†åˆ«æµç¨‹ï¼šå…ˆOCRï¼Œä½ç½®ä¿¡åº¦æ—¶å°è¯•LLMï¼ˆæ–°å¢ï¼‰"""
    logger.info("Processing with hybrid strategy...")
    
    # 1. å…ˆå°è¯•OCR
    ocr_result = self._process_with_ocr(image)
    
    # 2. æ£€æŸ¥OCRç½®ä¿¡åº¦
    ocr_confidence = ocr_result.get("spec", {}).get("confidence", 0.0)
    logger.info(f"OCR confidence: {ocr_confidence}")
    
    # 3. å¦‚æœOCRç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œç›´æ¥è¿”å›
    if ocr_result["success"] and ocr_confidence >= LLMConfig.OCR_CONFIDENCE_THRESHOLD:
        logger.info("OCR confidence is high enough, using OCR result")
        ocr_result["method"] = "ocr"
        return ocr_result
    
    # 4. OCRç½®ä¿¡åº¦ä½ï¼Œå°è¯•LLM
    logger.info("OCR confidence is low, trying LLM...")
    if self.llm_engine:
        llm_result = self._process_with_llm(image)
        
        if llm_result["success"]:
            llm_result["metadata"]["ocr_confidence"] = ocr_confidence
            llm_result["metadata"]["fallback_reason"] = "low_ocr_confidence"
            return llm_result
    
    # 5. LLMä¹Ÿå¤±è´¥ï¼Œè¿”å›OCRç»“æœï¼ˆå¸¦é™çº§æ ‡è®°ï¼‰
    logger.warning("LLM also failed, returning OCR result")
    ocr_result["method"] = "ocr"
    ocr_result["metadata"] = {"llm_attempted": True, "llm_failed": True}
    return ocr_result
```

æ·»åŠ æ–°çš„é”™è¯¯ç ï¼ˆåœ¨config.pyä¸­ï¼‰ï¼š

```python
class ErrorCode(str, Enum):
    # ... ç°æœ‰é”™è¯¯ç 
    LLM_NOT_CONFIGURED = "LLM_NOT_CONFIGURED"  # æ–°å¢
```

---

### Phase 3: APIä¸å‰ç«¯é›†æˆï¼ˆDay 4ï¼‰

#### Step 3.1: ä¿®æ”¹APIæ¥å£

**æ–‡ä»¶**: `spec_locator/api/server.py`

ä¿®æ”¹ `locate_spec` å‡½æ•°ï¼š

```python
from fastapi import Query  # æ·»åŠ å¯¼å…¥

@app.post("/api/spec-locate")
async def locate_spec(
    file: UploadFile = File(...),
    method: str = Query(
        default="ocr",
        regex="^(ocr|llm|auto)$",
        description="è¯†åˆ«æ–¹å¼: ocr-OCRè¯†åˆ«, llm-å¤§æ¨¡å‹è¯†åˆ«, auto-æ™ºèƒ½åˆ‡æ¢"
    )
):
    """
    è§„èŒƒå®šä½è¯†åˆ«æ¥å£ï¼ˆæ”¯æŒå¤šç§è¯†åˆ«æ–¹å¼ï¼‰

    Args:
        file: CAD æˆªå›¾æ–‡ä»¶
        method: è¯†åˆ«æ–¹å¼ (ocr/llm/auto)

    Returns:
        JSON å“åº”
    """
    if pipeline is None:
        raise HTTPException(status_code=503, detail="æœåŠ¡æ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åé‡è¯•")
    
    try:
        # 1. æ–‡ä»¶éªŒè¯ï¼ˆä¿æŒä¸å˜ï¼‰
        if not file:
            raise HTTPException(status_code=400, detail="No file provided")

        filename = file.filename.lower()
        if not any(filename.endswith(ext) for ext in APIConfig.ALLOWED_EXTENSIONS):
            return _error_response(ErrorCode.INVALID_FILE)

        contents = await file.read()
        if len(contents) > APIConfig.MAX_UPLOAD_SIZE:
            raise HTTPException(status_code=413, detail="File too large")

        # 2. è¯»å–å›¾åƒï¼ˆä¿æŒä¸å˜ï¼‰
        try:
            nparr = np.frombuffer(contents, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if image is None:
                return _error_response(ErrorCode.INVALID_FILE)
        except Exception as e:
            logger.error(f"Failed to decode image: {e}")
            return _error_response(ErrorCode.INVALID_FILE)

        # 3. æ ¹æ®methodå‚æ•°è®¾ç½®è¯†åˆ«æ–¹å¼
        original_method = pipeline.recognition_method
        pipeline.recognition_method = method
        
        # 4. è°ƒç”¨æµæ°´çº¿å¤„ç†
        logger.info(f"Processing file: {filename} with method: {method}")
        result = pipeline.process(image)
        
        # æ¢å¤åŸå§‹è®¾ç½®
        pipeline.recognition_method = original_method

        return JSONResponse(content=result)

    except HTTPException as e:
        logger.error(f"HTTP exception: {e}")
        return JSONResponse(
            status_code=e.status_code,
            content={
                "success": False,
                "error_code": "INVALID_REQUEST",
                "message": e.detail,
            },
        )
    except Exception as e:
        logger.error(f"Unexpected error: {e}", exc_info=True)
        return _error_response(ErrorCode.INTERNAL_ERROR)
```

#### Step 3.2: ä¿®æ”¹å‰ç«¯HTML

**æ–‡ä»¶**: `spec_locator/api/demo.html`

åœ¨ä¸Šä¼ åŒºåŸŸåæ·»åŠ è¯†åˆ«æ–¹å¼é€‰æ‹©å™¨ï¼ˆçº¦åœ¨ç¬¬100è¡Œå·¦å³ï¼‰ï¼š

```html
<!-- åœ¨ upload-area åæ·»åŠ  -->
<div class="method-selector">
    <h3>é€‰æ‹©è¯†åˆ«æ–¹å¼</h3>
    <div class="radio-group">
        <label class="radio-card">
            <input type="radio" name="method" value="ocr" checked>
            <div class="card-content">
                <div class="card-icon">âš¡</div>
                <div class="card-title">OCRè¯†åˆ«</div>
                <div class="card-desc">å¿«é€Ÿè¯†åˆ«ï¼Œé€‚åˆæ¸…æ™°å›¾åƒ</div>
                <div class="card-badge recommended">æ¨è</div>
            </div>
        </label>
        
        <label class="radio-card">
            <input type="radio" name="method" value="llm">
            <div class="card-content">
                <div class="card-icon">ğŸ¤–</div>
                <div class="card-title">å¤§æ¨¡å‹è¯†åˆ«</div>
                <div class="card-desc">æ™ºèƒ½è¯†åˆ«ï¼Œé€‚åˆå¤æ‚åœºæ™¯</div>
                <div class="card-badge accuracy">é«˜ç²¾åº¦</div>
            </div>
        </label>
        
        <label class="radio-card">
            <input type="radio" name="method" value="auto">
            <div class="card-content">
                <div class="card-icon">ğŸ¯</div>
                <div class="card-title">æ™ºèƒ½åˆ‡æ¢</div>
                <div class="card-desc">è‡ªåŠ¨é€‰æ‹©æœ€ä½³è¯†åˆ«æ–¹å¼</div>
                <div class="card-badge best">æœ€ä½³</div>
            </div>
        </label>
    </div>
</div>
```

æ·»åŠ æ ·å¼ï¼ˆåœ¨ `<style>` æ ‡ç­¾å†…ï¼‰ï¼š

```css
/* è¯†åˆ«æ–¹å¼é€‰æ‹©å™¨æ ·å¼ */
.method-selector {
    margin: 30px 0;
}

.method-selector h3 {
    font-size: 18px;
    margin-bottom: 15px;
    color: #333;
}

.radio-group {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 15px;
}

.radio-card {
    cursor: pointer;
    display: block;
}

.radio-card input[type="radio"] {
    display: none;
}

.card-content {
    border: 2px solid #e0e0e0;
    border-radius: 10px;
    padding: 20px;
    text-align: center;
    transition: all 0.3s;
    background: white;
    position: relative;
}

.radio-card input[type="radio"]:checked + .card-content {
    border-color: #667eea;
    background: #f0f2ff;
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
}

.card-icon {
    font-size: 36px;
    margin-bottom: 10px;
}

.card-title {
    font-size: 16px;
    font-weight: bold;
    color: #333;
    margin-bottom: 5px;
}

.card-desc {
    font-size: 12px;
    color: #666;
    margin-bottom: 10px;
}

.card-badge {
    display: inline-block;
    padding: 3px 10px;
    border-radius: 12px;
    font-size: 11px;
    font-weight: bold;
}

.card-badge.recommended {
    background: #ffd700;
    color: #333;
}

.card-badge.accuracy {
    background: #ff6b6b;
    color: white;
}

.card-badge.best {
    background: #51cf66;
    color: white;
}

.radio-card:hover .card-content {
    border-color: #667eea;
    transform: translateY(-2px);
}
```

ä¿®æ”¹JavaScriptæäº¤é€»è¾‘ï¼ˆåœ¨ `<script>` æ ‡ç­¾å†…ï¼‰ï¼š

```javascript
// ä¿®æ”¹ç°æœ‰çš„ uploadFile å‡½æ•°
async function uploadFile() {
    const fileInput = document.getElementById('fileInput');
    if (!fileInput.files[0]) {
        showNotification('è¯·å…ˆé€‰æ‹©æ–‡ä»¶', 'error');
        return;
    }
    
    // è·å–é€‰ä¸­çš„è¯†åˆ«æ–¹å¼
    const methodRadios = document.getElementsByName('method');
    let method = 'ocr';
    for (const radio of methodRadios) {
        if (radio.checked) {
            method = radio.value;
            break;
        }
    }
    
    const formData = new FormData();
    formData.append('file', fileInput.files[0]);
    
    // æ˜¾ç¤ºåŠ è½½çŠ¶æ€ï¼ˆæ ¹æ®methodæ˜¾ç¤ºä¸åŒæç¤ºï¼‰
    const loadingMessages = {
        'ocr': 'æ­£åœ¨å¿«é€Ÿè¯†åˆ«ä¸­...',
        'llm': 'å¤§æ¨¡å‹åˆ†æä¸­ï¼Œè¯·ç¨å€™ï¼ˆå¯èƒ½éœ€è¦3-5ç§’ï¼‰...',
        'auto': 'æ™ºèƒ½è¯†åˆ«ä¸­...'
    };
    showLoading(loadingMessages[method]);
    
    try {
        const response = await fetch(`http://localhost:8002/api/spec-locate?method=${method}`, {
            method: 'POST',
            body: formData
        });
        
        const result = await response.json();
        hideLoading();
        displayResult(result);
        
    } catch (error) {
        hideLoading();
        showNotification('è¯†åˆ«å¤±è´¥: ' + error.message, 'error');
    }
}

function displayResult(result) {
    // ä¿®æ”¹ç°æœ‰çš„displayResultå‡½æ•°ï¼Œæ˜¾ç¤ºmethodä¿¡æ¯
    const resultArea = document.querySelector('.result-area');
    const resultCard = document.querySelector('.result-card');
    
    if (result.success) {
        const methodLabels = {
            'ocr': 'OCRè¯†åˆ«',
            'llm': 'å¤§æ¨¡å‹è¯†åˆ«',
            'auto': 'æ™ºèƒ½è¯†åˆ«'
        };
        
        resultCard.innerHTML = `
            <div class="result-header">
                <h2>âœ“ è¯†åˆ«æˆåŠŸ</h2>
                <span class="method-badge">${methodLabels[result.method] || result.method}</span>
            </div>
            <div class="result-content">
                <div class="result-item">
                    <span class="label">è§„èŒƒç¼–å·ï¼š</span>
                    <span class="value">${result.spec.code}</span>
                </div>
                <div class="result-item">
                    <span class="label">é¡µç ï¼š</span>
                    <span class="value">${result.spec.page}</span>
                </div>
                <div class="result-item">
                    <span class="label">ç½®ä¿¡åº¦ï¼š</span>
                    <span class="value">${(result.spec.confidence * 100).toFixed(1)}%</span>
                </div>
                ${result.metadata?.llm_reasoning ? `
                <div class="result-item">
                    <span class="label">è¯†åˆ«ä¾æ®ï¼š</span>
                    <span class="value">${result.metadata.llm_reasoning}</span>
                </div>
                ` : ''}
                ${result.file?.exists ? `
                <a href="${result.file.download_url}" class="download-btn" target="_blank">
                    ğŸ“¥ ä¸‹è½½PDFæ–‡ä»¶
                </a>
                ` : ''}
            </div>
        `;
    } else {
        // é”™è¯¯æ˜¾ç¤ºé€»è¾‘...
    }
    
    resultArea.style.display = 'block';
}

// æ·»åŠ method badgeæ ·å¼
```

æ·»åŠ é¢å¤–CSSï¼š

```css
.method-badge {
    display: inline-block;
    padding: 5px 12px;
    background: rgba(255, 255, 255, 0.3);
    border-radius: 15px;
    font-size: 12px;
    font-weight: bold;
}

.result-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 20px;
}
```

---

### Phase 4: é…ç½®ä¸æ–‡æ¡£ï¼ˆDay 5ï¼‰

#### Step 4.1: åˆ›å»ºç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶

**æ–‡ä»¶**: `spec_locator/.env.example`

```bash
# ===== åŸºç¡€é…ç½® =====
DEBUG=false
LOG_LEVEL=INFO

# ===== æ•°æ®ç›®å½• =====
SPEC_DATA_DIR=../output_pages

# ===== APIé…ç½® =====
API_HOST=0.0.0.0
API_PORT=8002
API_WORKERS=4

# ===== OCRé…ç½® =====
OCR_USE_GPU=false
OCR_PRECISION=fp32
OCR_CONF_THRESHOLD=0.3
OCR_LAZY_LOAD=true
OCR_WARMUP_ON_STARTUP=false

# ===== å¤§æ¨¡å‹é…ç½®ï¼ˆæ–°å¢ï¼‰=====
LLM_ENABLED=true
DOUBAO_API_KEY=your_doubao_api_key_here
LLM_MODEL=doubao-vision-pro
LLM_TIMEOUT=30
LLM_MAX_RETRIES=2

# æ··åˆæ¨¡å¼é…ç½®
LLM_AUTO_FALLBACK=true
OCR_CONFIDENCE_THRESHOLD=0.6

# Promptç‰ˆæœ¬
LLM_PROMPT_VERSION=v1
```

#### Step 4.2: æ›´æ–°README

**æ–‡ä»¶**: `spec_locator/LLM_README.md` (æ–°å»ºä½¿ç”¨è¯´æ˜)

```markdown
# å¤§æ¨¡å‹è¯†åˆ«åŠŸèƒ½ä½¿ç”¨æŒ‡å—

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install volcenginesdkarkruntime tenacity
```

### 2. é…ç½®APIå¯†é’¥

```bash
# æ–¹å¼1ï¼šç¯å¢ƒå˜é‡
export DOUBAO_API_KEY=your_api_key_here

# æ–¹å¼2ï¼š.envæ–‡ä»¶
echo "DOUBAO_API_KEY=your_api_key_here" >> .env
```

### 3. å¯åŠ¨æœåŠ¡

```bash
uvicorn spec_locator.api.server:app --host 0.0.0.0 --port 8002
```

### 4. è®¿é—®æ¼”ç¤ºé¡µé¢

æ‰“å¼€æµè§ˆå™¨ï¼šhttp://localhost:8002/docs
æˆ–ä½¿ç”¨æ¼”ç¤ºé¡µé¢ï¼šfile:///D:/projects/liuzong/spec_locator/api/demo.html

## ä½¿ç”¨æ–¹å¼

### æ–¹å¼1ï¼šé€šè¿‡å‰ç«¯ç•Œé¢

1. æ‰“å¼€demo.html
2. é€‰æ‹©è¯†åˆ«æ–¹å¼ï¼ˆOCR/å¤§æ¨¡å‹/æ™ºèƒ½åˆ‡æ¢ï¼‰
3. ä¸Šä¼ CADæˆªå›¾
4. æŸ¥çœ‹è¯†åˆ«ç»“æœ

### æ–¹å¼2ï¼šé€šè¿‡APIè°ƒç”¨

```python
import requests

url = "http://localhost:8002/api/spec-locate"
files = {"file": open("screenshot.png", "rb")}
params = {"method": "llm"}  # æˆ– "ocr" / "auto"

response = requests.post(url, files=files, params=params)
result = response.json()
print(result)
```

## è¯†åˆ«æ–¹å¼å¯¹æ¯”

| æ–¹å¼ | é€Ÿåº¦ | å‡†ç¡®ç‡ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ |
|-----|------|-------|---------|-----|
| OCR | âš¡ å¿« | ä¸­ç­‰ | æ¸…æ™°æ ‡å‡†å›¾åƒ | å…è´¹ |
| å¤§æ¨¡å‹ | ğŸ¢ æ…¢ | é«˜ | å¤æ‚æ¨¡ç³Šå›¾åƒ | ä»˜è´¹ |
| æ™ºèƒ½åˆ‡æ¢ | âš–ï¸ é€‚ä¸­ | é«˜ | é€šç”¨åœºæ™¯ | æŒ‰éœ€ |

## é…ç½®è¯´æ˜

è¯¦è§ `.env.example` æ–‡ä»¶

## å¸¸è§é—®é¢˜

### Q: å¤§æ¨¡å‹è¯†åˆ«å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: ç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°OCRè¯†åˆ«ï¼ˆautoæ¨¡å¼ä¸‹ï¼‰

### Q: å¦‚ä½•æé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼Ÿ
A: 1) ä½¿ç”¨å¤§æ¨¡å‹è¯†åˆ« 2) ç¡®ä¿å›¾ç‰‡æ¸…æ™° 3) è°ƒæ•´Promptç‰ˆæœ¬

### Q: APIæˆæœ¬å¦‚ä½•æ§åˆ¶ï¼Ÿ
A: é»˜è®¤ä½¿ç”¨OCRï¼Œä»…åœ¨éœ€è¦æ—¶é€‰æ‹©å¤§æ¨¡å‹

## æ›´å¤šä¿¡æ¯

è¯¦è§ï¼š
- è®¾è®¡æ–‡æ¡£ï¼šLLM_INTEGRATION_DESIGN.md
- å¼€å‘æŒ‡å—ï¼šLLM_INTEGRATION_GUIDE.md
```

---

## ä¸‰ã€æµ‹è¯•ä¸éªŒè¯

### 3.1 å•å…ƒæµ‹è¯•è¿è¡Œ

```bash
cd spec_locator
pytest tests/test_llm_module.py -v
```

### 3.2 é›†æˆæµ‹è¯•

```python
# tests/integration/test_full_flow.py
import cv2
import numpy as np

def test_llm_recognition_flow():
    """æµ‹è¯•å®Œæ•´çš„LLMè¯†åˆ«æµç¨‹"""
    # åŠ è½½æµ‹è¯•å›¾ç‰‡
    image = cv2.imread("test_images/sample.png")
    
    # åˆå§‹åŒ–Pipeline
    pipeline = SpecLocatorPipeline(recognition_method="llm")
    
    # æ‰§è¡Œè¯†åˆ«
    result = pipeline.process(image)
    
    # éªŒè¯ç»“æœ
    assert result["success"] == True
    assert result["spec"]["code"] is not None
    assert result["spec"]["page"] is not None
```

### 3.3 æ‰‹åŠ¨æµ‹è¯•æ¸…å•

- [ ] OCRæ¨¡å¼ï¼šä¸Šä¼ æ¸…æ™°å›¾ç‰‡ï¼ŒéªŒè¯è¯†åˆ«
- [ ] LLMæ¨¡å¼ï¼šä¸Šä¼ æ¨¡ç³Šå›¾ç‰‡ï¼ŒéªŒè¯è¯†åˆ«
- [ ] Autoæ¨¡å¼ï¼šä¸Šä¼ ä¸åŒè´¨é‡å›¾ç‰‡ï¼ŒéªŒè¯åˆ‡æ¢é€»è¾‘
- [ ] é”™è¯¯å¤„ç†ï¼šæµ‹è¯•APIå¯†é’¥é”™è¯¯ã€è¶…æ—¶ç­‰
- [ ] å‰ç«¯äº¤äº’ï¼šéªŒè¯UIé€‰æ‹©å’Œç»“æœæ˜¾ç¤º

---

## å››ã€éƒ¨ç½²ä¸å‘å¸ƒ

### 4.1 éƒ¨ç½²å‰æ£€æŸ¥

```bash
# 1. æ£€æŸ¥ä¾èµ–
pip list | grep -E "volcengine|tenacity"

# 2. éªŒè¯é…ç½®
python -c "from spec_locator.config import LLMConfig; print(LLMConfig.validate())"

# 3. æµ‹è¯•APIè¿æ¥
python -c "from spec_locator.llm import DoubaoEngine; e = DoubaoEngine(); print('OK')"
```

### 4.2 å¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼1ï¼šç›´æ¥å¯åŠ¨
uvicorn spec_locator.api.server:app --host 0.0.0.0 --port 8002

# æ–¹å¼2ï¼šä½¿ç”¨å¯åŠ¨è„šæœ¬
./start_demo.bat
```

### 4.3 å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8002/health
```

é¢„æœŸè¿”å›ï¼š
```json
{
    "status": "ok",
    "index_stats": {...},
    "ocr_loaded": true,
    "llm_enabled": true
}
```

---

## äº”ã€æ•…éšœæ’æŸ¥

### 5.1 å¸¸è§é—®é¢˜

#### é—®é¢˜1: ModuleNotFoundError: No module named 'volcenginesdkarkruntime'

**è§£å†³**ï¼š
```bash
pip install volcenginesdkarkruntime
```

#### é—®é¢˜2: LLM_NOT_CONFIGURED é”™è¯¯

**åŸå› **ï¼šAPIå¯†é’¥æœªé…ç½®

**è§£å†³**ï¼š
```bash
export DOUBAO_API_KEY=your_key
# æˆ–åœ¨.envæ–‡ä»¶ä¸­é…ç½®
```

#### é—®é¢˜3: LLM_TIMEOUT è¶…æ—¶

**åŸå› **ï¼šç½‘ç»œæ…¢æˆ–æ¨¡å‹å“åº”æ…¢

**è§£å†³**ï¼š
- å¢åŠ è¶…æ—¶æ—¶é—´ï¼š`LLM_TIMEOUT=60`
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- åˆ‡æ¢åˆ°OCRæ¨¡å¼

#### é—®é¢˜4: å“åº”è§£æå¤±è´¥

**åŸå› **ï¼šå¤§æ¨¡å‹è¿”å›æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ

**è§£å†³**ï¼š
- æ£€æŸ¥`raw_response`å­—æ®µ
- è°ƒæ•´Promptç‰ˆæœ¬
- æŸ¥çœ‹æ—¥å¿—ä¸­çš„è§£æè¯¦æƒ…

### 5.2 æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
tail -f logs/app.log | grep -E "ERROR|LLM"

# æŸ¥çœ‹è¯†åˆ«æµç¨‹
tail -f logs/app.log | grep -E "Processing with|recognition"
```

---

## å…­ã€æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¹¶å‘æ§åˆ¶**ï¼šé™åˆ¶LLMåŒæ—¶è¯·æ±‚æ•°ï¼ˆé¿å…é…é¢è¶…é™ï¼‰
2. **ç»“æœç¼“å­˜**ï¼šç›¸åŒå›¾ç‰‡é¿å…é‡å¤è°ƒç”¨ï¼ˆå¯é€‰ï¼‰
3. **è¶…æ—¶ä¿æŠ¤**ï¼šè®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
4. **é™çº§ç­–ç•¥**ï¼šç¡®ä¿LLMå¤±è´¥æ—¶èƒ½æ­£å¸¸å·¥ä½œ

---

## ä¸ƒã€åç»­è¿­ä»£è®¡åˆ’

### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
- [ ] æ”¶é›†ç”¨æˆ·åé¦ˆï¼Œä¼˜åŒ–Prompt
- [ ] å¢åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹
- [ ] å®Œå–„é”™è¯¯æç¤ºä¿¡æ¯

### ä¸­æœŸï¼ˆ1-2ä¸ªæœˆï¼‰
- [ ] å®ç°ç»“æœç¼“å­˜
- [ ] æ·»åŠ è¯†åˆ«å†å²è®°å½•
- [ ] ä¼˜åŒ–å‰ç«¯äº¤äº’ä½“éªŒ

### é•¿æœŸï¼ˆ3-6ä¸ªæœˆï¼‰
- [ ] æ¢ç´¢æ›´å¤šå¤§æ¨¡å‹
- [ ] å®ç°æ™ºèƒ½è·¯ç”±ç®—æ³•
- [ ] è€ƒè™‘éƒ¨ç½²æœ¬åœ°æ¨¡å‹

---

## é™„å½•ï¼šå¼€å‘èµ„æº

### ç›¸å…³æ–‡æ¡£
- [è±†åŒ…APIæ–‡æ¡£](https://www.volcengine.com/docs/82379/1298454)
- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Tenacityæ–‡æ¡£](https://tenacity.readthedocs.io/)

### ä»£ç ç¤ºä¾‹
è§ `spec_locator/examples/llm_recognition_example.py`

### è”ç³»æ–¹å¼
å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤Issueæˆ–è”ç³»å¼€å‘å›¢é˜Ÿ

---

**æœ€åæ›´æ–°**: 2026-01-28
